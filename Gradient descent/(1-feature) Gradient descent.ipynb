{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b738bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1babc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data.csv\", delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453c61d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape # 2 columns 'X' <--- input & 'Y' <--- output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1477526a",
   "metadata": {},
   "source": [
    "#### For 1 - feature our regression model will be \"Y = mx + c\",  for n - features it become \"Y = m0 * x0 + m1 * x1 + ..... + mn * xn\"  considering x0 as dummy feature => x0 = 1, (therefore m0 * x0) will work as an intercept. for n - features we have to find m0, m1,..., mn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee5e4be",
   "metadata": {},
   "source": [
    "### OBJECTIVE : CREATING OWN GRADIENT DESCENT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa56d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update m & c at each gradient step -----> Try'in finding optimal\n",
    "\"\"\" cost = (1/M) * sum((Y_actual - Y_pred)**2) where Y_pred = m*x + c, Here M = no. of training example\n",
    "(coz for N-features, we use no. of training examples as M), m_slope: d(cost)/d(m)  &   c_slope: d(cost)/d(c)\n",
    "m_slope: (-2/M) * sum(Y_actual - m*x - c)*x   &   c_slope: (-2/M) * sum(Y_actual - m*x - c)\"\"\"\n",
    "\n",
    "def step_gradient(data, learning_rate, m, c):\n",
    "    m_slope = 0; c_slope = 0; M = len(data)\n",
    "    for i in range(M):\n",
    "        x = data[i, 0]\n",
    "        y = data[i, 1]\n",
    "        m_slope += (-2/M)*(y - m*x - c)*x\n",
    "        c_slope += (-2/M)*(y - m*x - c)\n",
    "    new_m = m - learning_rate * m_slope\n",
    "    new_c = c - learning_rate * c_slope\n",
    "    return new_m, new_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9205a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function to verify wheather given learning_rate, iteration is good enough for data\n",
    "\n",
    "def cost(data, m, c):\n",
    "    total_cost = 0; M = len(data)\n",
    "    for i in range(M):\n",
    "        x = data[i, 0]; y = data[i, 1]\n",
    "        total_cost += (1/M)*((y - m*x - c)**2)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d1af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will find optimal m & c(update them) then print it\n",
    "\n",
    "def own_gradient_descent(data, learning_rate, iteration) :\n",
    "    m = 0; c = 0\n",
    "    for i in range(iteration):\n",
    "        m, c = step_gradient(data, learning_rate, m, c)\n",
    "        print(i, \"Cost : \", cost(data, m, c)) # Cost for this m & c\n",
    "    print(m, c) # updated m & c after all gradient descent steps taken\n",
    "\n",
    "# If cost is looks constant after certain iteration ==> We're near about optimal we update \n",
    "# the learning rate & iteration(or no. of descent steps) in order to come close to least cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89e1065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost :  1484.5865574086486\n",
      "1 Cost :  457.8542575737672\n",
      "2 Cost :  199.5099857255389\n",
      "3 Cost :  134.50591058200533\n",
      "4 Cost :  118.1496934223995\n",
      "5 Cost :  114.0341490603815\n",
      "6 Cost :  112.99857731713657\n",
      "7 Cost :  112.73798187568467\n",
      "8 Cost :  112.6723843590911\n",
      "9 Cost :  112.65585181499745\n",
      "1.47741737554838 0.029639347874732384\n"
     ]
    }
   ],
   "source": [
    "own_gradient_descent(data, 0.0001, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
